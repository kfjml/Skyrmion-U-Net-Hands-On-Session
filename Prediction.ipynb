{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e92294-d292-4371-a0e5-a1c405a67722",
   "metadata": {},
   "source": [
    "# Skyrmion U-Net prediction & analysis example\n",
    "\n",
    "## Import packages + define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f11eec-d152-48fb-85f0-76e0e27b13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.spatial\n",
    "import glob\n",
    "import io\n",
    "import pandas as pd\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.style.use('seaborn-v0_8-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650175c-7387-47aa-a5f6-c7777d5864f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = lambda : len(tf.config.list_physical_devices('GPU'))\n",
    "if gpu_available(): print(\"GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44317847-0260-4e5d-bd37-61714d303482",
   "metadata": {},
   "source": [
    "# U-Net architecture\n",
    "The U-Net models in this repository were trained to predict on 512x512 Kerr microscopy images.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243aca3e-9297-4e74-bace-6ac097827a73",
   "metadata": {},
   "source": [
    "![](notebook_figures/u_net_architecture_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f66a8-8aca-48a0-a55d-c2fa104cc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic activation layer\n",
    "class MishLayer(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        return tf.keras.activations.mish(x)\n",
    "\n",
    "# Basic Convolution Block\n",
    "def conv_block(x, n_channels, param):\n",
    "    x = tf.keras.layers.Conv2D(n_channels, kernel_size=param[\"kernel_size\"],kernel_initializer=param[\"kernel_initialization\"],padding=\"same\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = MishLayer()(x)\n",
    "    return x\n",
    "\n",
    "# Double Convolution Block used in \"encoder\" and \"bottleneck\"\n",
    "def double_conv_block(x, n_channels, param):\n",
    "    x = conv_block(x,n_channels,param)\n",
    "    x = conv_block(x,n_channels,param)\n",
    "    return x\n",
    "\n",
    "# Downsample block for feature extraction (encoder)\n",
    "def downsample_block(x, n_channels, param):\n",
    "    f = double_conv_block(x, n_channels, param)\n",
    "    p = tf.keras.layers.MaxPool2D(pool_size=(2,2))(f)\n",
    "    p = tf.keras.layers.Dropout(param[\"dropout\"])(p)\n",
    "    return f, p\n",
    "\n",
    "# Upsample block for the decoder\n",
    "def upsample_block(x, conv_features, n_channels, param):\n",
    "    x = tf.keras.layers.Conv2DTranspose(n_channels*param[\"upsample_channel_multiplier\"], param[\"kernel_size\"], strides=(2,2), padding='same')(x)\n",
    "    x = tf.keras.layers.concatenate([x, conv_features])\n",
    "    x = tf.keras.layers.Dropout(param[\"dropout\"])(x)\n",
    "    x = double_conv_block(x, n_channels, param)\n",
    "    return x\n",
    "\n",
    "# Create the model\n",
    "def get_unet(param):\n",
    "    input = tf.keras.layers.Input(shape=param[\"input_shape\"]+(1,))\n",
    "    next_input = input\n",
    "    \n",
    "    l_residual_con = []\n",
    "    for i in range(param[\"n_depth\"]):\n",
    "        residual_con,next_input = downsample_block(next_input, (2**i)*param[\"filter_multiplier\"],param)\n",
    "        l_residual_con.append(residual_con)\n",
    "\n",
    "    next_input = double_conv_block(next_input, (2**param[\"n_depth\"])*param[\"filter_multiplier\"],param)\n",
    "\n",
    "    for i in range(param[\"n_depth\"]):\n",
    "        next_input = upsample_block(next_input, l_residual_con[param[\"n_depth\"]-1-i], (2**(param[\"n_depth\"]-1-i))*param[\"filter_multiplier\"],param)\n",
    "\n",
    "    output = tf.keras.layers.Conv2D(param[\"n_class\"], (1,1), padding=\"same\", activation = \"softmax\",dtype='float32')(next_input)    \n",
    "    \n",
    "    return tf.keras.Model(input, output, name=param[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9effd-c90d-42f1-bc58-55b80a560f6b",
   "metadata": {},
   "source": [
    "U-Net can be described as follows:\n",
    "\n",
    "$$ \\mathbf{z} = \\mathbf{f}_{\\vec{\\theta}}(\\mathbf{x}) $$\n",
    "\n",
    "where $\\vec{\\theta}$ is a high-dimensional vector containing all parameters, $\\mathbf{z}$ is a 3-dimensional output tensor, and $\\mathbf{x}$ is the input Kerr microscopy image. In $\\mathbf{f}$ are encapsulated all the operations such as convolution, max pooling, up-convolution, batch normalization, ... .\n",
    "\n",
    "$\\mathbf{z}$ is converted to probabilities using softmax:\n",
    "\n",
    "$$ p_{(x,y),i} = \\frac{\\exp(\\mathbf{z}_{(x,y),i})}{\\sum_{i\\in \\mathrm{classes}} \\exp(\\mathbf{z}_{(x,y),i})} $$\n",
    "\n",
    "The output mask $\\mathbf{m}$ is then determined by:\n",
    "\n",
    "$$ \\mathbf{m}_{(x,y)} = \\mathrm{arg\\,max}_i\\; p_{\\mathrm{U-Net}}(\\mathbf{z}_{(x,y),i}). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0dba99-0326-4169-be2d-628dd4313c90",
   "metadata": {},
   "source": [
    "# Mask index $\\leftrightarrow$ RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffcd3e5-b88e-4905-8be2-5a6093baa701",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "Labels for U-Net model:\n",
    "- Skyrmions (RGB-label: red (255,0,0))\n",
    "- Defects (RGB-label: green (0,255,0)\n",
    "- FM background (RGB-label: blue (0,0,255))\n",
    "- Non-FM background (RGB-label: yellow (255,255,0))\n",
    "- Boundary non-FM/FM background (RGB-label: cyan (0,255,255))\n",
    "\n",
    "The 3-class U-Net model predicts skyrmions (RGB-label: red (255,0,0)), defects (RGB-label: blue (0,255,0)), and background (RGB-label: blue (0,0,255)). The background consists of the ferromagnetic background, non-ferromagnetic background, and the boundary between ferromagnetic and non-ferromagnetic background. The RGB-label is converted to an class index for training. For model 2022 the class indeces are (skyrmions:0, defects:1, background:2), for model 2023 the class indeces are (skyrmions:0, background:1, defects:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a425362-e525-440e-9276-7d02e1b4ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trafo_channel_to_rgb(I):\n",
    "    basis = np.array([[255,0,0],[0,255,0],[0,0,255]],dtype=np.uint8)\n",
    "    return basis[I]\n",
    "\n",
    "def trafo_rgb_to_channel(I):\n",
    "    Q = np.zeros((I.shape[0],I.shape[1]),dtype=np.uint8)\n",
    "    R,G,B = I[:,:,0],I[:,:,1],I[:,:,2]\n",
    "    skyrmion_mask = (R>=128)&(G<128)&(B<128)\n",
    "    defect_mask = (R<128)&(G>=128)&(B<128)\n",
    "    bck_mask = ~(skyrmion_mask|defect_mask)\n",
    "    Q[skyrmion_mask] = 0\n",
    "    Q[defect_mask] = 1\n",
    "    Q[bck_mask] = 2\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c20477-9d0e-4911-9113-5f8b570c05de",
   "metadata": {},
   "source": [
    "# Prediction with U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb147800-25f8-4452-bb44-994e081f5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the label based on Kerr images and the U-Net model.\n",
    "def predict(x,fn_model,batch_size=5,normalize_255=True):\n",
    "    #load U-Net model\n",
    "    model = tf.keras.models.load_model(fn_model,compile=False,custom_objects={'MishLayer': MishLayer})\n",
    "    \n",
    "    if not gpu_available():\n",
    "        #create identical model, only with pure float_32 policy\n",
    "        batch_size = 1\n",
    "        nmodel = get_unet({\"name\":\"unet\",\"input_shape\": (512,512), \"n_class\":3,\"filter_multiplier\":16,\"n_depth\":4,\n",
    "                  \"kernel_initialization\":\"he_normal\",\"dropout\":0.1,\"kernel_size\":(3,3),\"upsample_channel_multiplier\":8})\n",
    "        nmodel.set_weights(model.weights)\n",
    "        model = nmodel\n",
    "    \n",
    "    n = int(np.ceil(len(x)/batch_size))\n",
    "    lix = [np.array(range(j*batch_size,min((j+1)*batch_size,len(x)))) for j in range(n)]\n",
    "    ylabel = np.zeros(x.shape,dtype=np.uint8)\n",
    "    progbar = tf.keras.utils.Progbar(n)\n",
    "    for i in range(n):            \n",
    "        progbar.update(i)\n",
    "        input = x[lix[i]]\n",
    "        if normalize_255:\n",
    "            input = input/255\n",
    "        ylabel[lix[i]] = model.predict(input,verbose=False).argmax(-1)\n",
    "    progbar.update(n,finalize=True)\n",
    "    return ylabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20959032-abbd-4b8c-b56e-7fb0d7b416c0",
   "metadata": {},
   "source": [
    "# Validation - Matthews correlation coefficient (MCC)\n",
    "$$\\mathrm{MCC} = \\frac{\\mathrm{TP} \\cdot \\mathrm{TN} - \\mathrm{FP} \\cdot \\mathrm{FN}}{\\sqrt{(\\mathrm{TP} + \\mathrm{FP})(\\mathrm{FN} + \\mathrm{TN})(\\mathrm{TP} + \\mathrm{FN})(\\mathrm{FP} + \\mathrm{TN})}}$$\n",
    "with the number of true positives $\\mathrm{TP}$, true negatives $\\mathrm{TN}$, false positives $\\mathrm{FP}$, and false negatives $\\mathrm{FN}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eee836-f701-4e15-888b-13b44a0d90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF_PN(y_true,y_pred,ix0):\n",
    "    m1,m2 = y_true==ix0,y_pred==ix0\n",
    "    im1,im2 = tf.math.logical_not(m1),tf.math.logical_not(m2)\n",
    "    TP = tf.math.reduce_mean(tf.cast(tf.math.logical_and(m1,m2),dtype=np.float64))\n",
    "    TN = tf.math.reduce_mean(tf.cast(tf.math.logical_and(im1,im2),dtype=np.float64))\n",
    "    FP = tf.math.reduce_mean(tf.cast(tf.math.logical_and(im1,m2),dtype=np.float64))\n",
    "    FN = tf.math.reduce_mean(tf.cast(tf.math.logical_and(m1,im2),dtype=np.float64))\n",
    "    return TP,TN,FP,FN\n",
    "\n",
    "def get_mcc_from_TF_PN(TP,TN,FP,FN):\n",
    "    denom = tf.keras.ops.sqrt((TP + FN) * (FP + TN) * (FP + TP) * (FN + TN))\n",
    "    val = (TP * TN - FP * FN) / denom\n",
    "    return  tf.where(tf.equal(denom, 0), tf.constant(0, dtype=tf.float64), val)\n",
    "\n",
    "def get_mcc(y_true,y_false,n_class):\n",
    "    return get_mcc_from_TF_PN(*get_TF_PN(y_true,y_false,n_class)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d59683-b1ea-4ca4-82bd-f18e04fa2c4e",
   "metadata": {},
   "source": [
    "# Prediction of Kerr microscopy images from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a00083b-01c7-4423-85c0-a05474f26541",
   "metadata": {},
   "source": [
    "## Load filenames of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ae334-8ebe-4485-b38a-8c93542e4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/table.csv\",sep=\";\")\n",
    "fnimg,fnlabel = list(dataset.img_fn.to_numpy()),list(dataset.label_fn.to_numpy())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c784b3-c6e1-49a5-9936-493c371cdd42",
   "metadata": {},
   "source": [
    "## Model 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4040a-8fe1-4378-8891-208cb53ed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load imag and label\n",
    "ix = 129\n",
    "img = np.array(Image.open(fnimg[ix]))\n",
    "label = np.array(Image.open(fnlabel[ix]))\n",
    "#cut to 512x512\n",
    "img,label = img[:512,:512],label[:512,:512]\n",
    "#Predict label with U-Net\n",
    "predicted_label = predict(np.array([img]),\"models/2023_model.keras\",batch_size=1)[0]\n",
    "#Swap class index of 1 and 2, since for model 2023 the class indeces are (skyrmion:0, background:1, defects:2) and the functions are written for class indeces (skyrmion:0, defects:1, background:2)\n",
    "predicted_label[predicted_label==1] = 5\n",
    "predicted_label[predicted_label==2] = 1\n",
    "predicted_label[predicted_label==5] = 2\n",
    "#Evaluate predicitionn with Matthews correlation coefficient\n",
    "print(\"Pixelwise Matthews correlation coefficient (true=skyrmion,false=defect,background)\",get_mcc(trafo_rgb_to_channel(label),predicted_label,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd521313-16b8-42f6-9d3d-f5373e3db1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "\n",
    "fig,ax = plt.subplots(ncols=3,dpi=300)\n",
    "ax[0].imshow(img,cmap=\"gray\")\n",
    "ax[1].imshow(label)\n",
    "ax[2].imshow(trafo_channel_to_rgb(predicted_label))\n",
    "ax[0].set_title(\"Kerr image\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Predicted label\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c3496-587f-4866-b31f-dc0520c1af57",
   "metadata": {},
   "source": [
    "## Model 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea955e65-e7ac-49be-a4ef-5c5638856d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load imag and label\n",
    "ix = 78\n",
    "img = np.array(Image.open(fnimg[ix]))\n",
    "label = np.array(Image.open(fnlabel[ix]))\n",
    "#cut to 512x512\n",
    "img,label = img[:512,:512],label[:512,:512]\n",
    "#Predict label with U-Net\n",
    "predicted_label = predict(np.array([img]),\"models/2022_model.keras\",batch_size=1)[0]\n",
    "#Evaluate predicitionn with Matthews correlation coefficient\n",
    "print(\"Pixelwise Matthews correlation coefficient (true=skyrmion,false=defect,background)\",get_mcc(trafo_rgb_to_channel(label),predicted_label,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7d6f-e369-48fd-85f8-09e61b69ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "\n",
    "fig,ax = plt.subplots(ncols=3,dpi=300)\n",
    "ax[0].imshow(img,cmap=\"gray\")\n",
    "ax[1].imshow(label)\n",
    "ax[2].imshow(trafo_channel_to_rgb(predicted_label))\n",
    "ax[0].set_title(\"Kerr image\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Predicted label\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f99ee-769e-458d-90fa-28873ad6cd7c",
   "metadata": {},
   "source": [
    "## Model Inversion 2022\n",
    "Model that also functions on Kerr microscopy images with normal and inverted intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863d7fb-aa47-4c77-983a-a262e47f0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load imag and label\n",
    "ix = 1\n",
    "img = 255-np.array(Image.open(fnimg[ix]))\n",
    "label = np.array(Image.open(fnlabel[ix]))\n",
    "#cut to 512x512\n",
    "img,label = img[:512,:512],label[:512,:512]\n",
    "#Predict label with U-Net\n",
    "predicted_label = predict(np.array([img]),\"models/2022_model_inv.keras\",batch_size=1)[0]\n",
    "#Evaluate predicitionn with Matthews correlation coefficient\n",
    "print(\"Pixelwise Matthews correlation coefficient (true=skyrmion,false=defect,background)\",get_mcc(trafo_rgb_to_channel(label),predicted_label,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c14daf-6f25-4859-8911-a99f4f02db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "\n",
    "fig,ax = plt.subplots(ncols=3,dpi=300)\n",
    "ax[0].imshow(img,cmap=\"gray\")\n",
    "ax[1].imshow(label)\n",
    "ax[2].imshow(trafo_channel_to_rgb(predicted_label))\n",
    "ax[0].set_title(\"Kerr image\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Predicted label\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd332b5-e9c5-4732-be82-033558c22354",
   "metadata": {},
   "source": [
    "# Skyrmion U-Net prediction & anaylsis of a (own) Kerr microscopy image\n",
    "\n",
    "Example Kerr microscopy image for this section courtesy of Dr. E. Martin Jefremovas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e398b9-51b1-4f77-89d6-377e83c0fb13",
   "metadata": {},
   "source": [
    "## Load & edit Kerr microscopy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1792ef8-edad-4a25-98c8-15c5f8da50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def manip(config):\n",
    "    invert = config[\"inv\"]\n",
    "    x0,x1 = config[\"xc\"]\n",
    "    y0,y1 = config[\"yc\"]\n",
    "    img = config[\"input_img\"].copy()\n",
    "    if len(img.shape)>2:\n",
    "        img =  np.mean(img,axis=-1)\n",
    "        \n",
    "    img = img[int(np.floor(y0)):int(np.ceil(y1)),int(np.floor(x0)):int(np.ceil(x1))]\n",
    "    img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
    "    \n",
    "    if invert:\n",
    "        img = 1-img\n",
    "    v0,v1 = config[\"intensity_clip\"]\n",
    "    nimg = np.clip(img,v0,v1)\n",
    "    config[\"edited_img\"] = np.clip(1/(v1-v0)*(img-v0),0,1)\n",
    "    config[\"histinfo\"] = img\n",
    "    config[\"show_img\"] = nimg\n",
    "\n",
    "\n",
    "input_img = np.array(Image.open(\"example_kerr_microscopy_image.png\"))\n",
    "config_init = {\"inv\":False,\"intensity_clip\":(0,1),\"xc\":(0,input_img.shape[1]),\"yc\":(0,input_img.shape[0]),\"input_img\":input_img}\n",
    "config = config_init.copy()\n",
    "\n",
    "with plt.ioff():\n",
    "    fig1,ax1 = plt.subplots(dpi=100)\n",
    "    fig2,ax2 = plt.subplots(dpi=100,figsize=(2,2))\n",
    "    fig1.canvas.header_visible = False\n",
    "    fig2.canvas.header_visible = False\n",
    "    \n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.grid(False)\n",
    "cmg = matplotlib.colormaps.get_cmap(\"gray\")\n",
    "clis = cmg(np.arange(cmg.N))\n",
    "clis[0] = [1,0,0,1]\n",
    "clis[-1] = [0,0,1,1]\n",
    "ncmap = matplotlib.colors.ListedColormap(clis)\n",
    "emptyimg = np.zeros((20,20)) #for initalisation of code only\n",
    "im1 = ax1.imshow(emptyimg,cmap=ncmap,vmin=0,vmax=1)\n",
    "cax = make_axes_locatable(ax1).append_axes(\"right\",size = \"2%\",pad=0.03)\n",
    "colb = plt.colorbar(im1,cax=cax)\n",
    "bins = np.linspace(0,1,40)\n",
    "_,_,hist = ax2.hist(emptyimg.flatten(),bins=bins,density=True)\n",
    "ax2.set_xlim(0,1)\n",
    "lowerl = ax2.axvline(0,color=\"red\")\n",
    "higherl = ax2.axvline(1,color=\"blue\")\n",
    "ax2.set_xlabel(\"Intensity\")\n",
    "fig2.tight_layout()\n",
    "\n",
    "def update_1(canvasdraw=True):\n",
    "    manip(config)\n",
    "    img = config[\"show_img\"]\n",
    "    histinfo = config[\"histinfo\"]\n",
    "    \n",
    "    im1.set_data(img)\n",
    "    im1.set_extent((config[\"xc\"][0],config[\"xc\"][1],config[\"yc\"][1],config[\"yc\"][0]))\n",
    "    \n",
    "    lowerl.set_xdata([config[\"intensity_clip\"][0],config[\"intensity_clip\"][0]])\n",
    "    higherl.set_xdata([config[\"intensity_clip\"][1],config[\"intensity_clip\"][1]])\n",
    "    ax1.set_aspect(1)\n",
    "    \n",
    "    v0,v1 = config[\"intensity_clip\"]\n",
    "    im1.set_clim(v0,v1)\n",
    "    colb.update_normal(im1)\n",
    "    #hist.set_data(config[\"input_img\"].copy().flatten())\n",
    "    nhist = np.histogram(histinfo,bins,density=True)[0]\n",
    "    for i,ele in enumerate(hist):\n",
    "        ele.set_height(nhist[i])\n",
    "    ax2.set_ylim(0,np.max(nhist)*1.1)\n",
    "    \n",
    "    if canvasdraw:\n",
    "        fig1.canvas.draw()\n",
    "        fig2.canvas.draw()\n",
    "    \n",
    "def update_img(inital_img):\n",
    "    config[\"input_img\"] = inital_img\n",
    "    resetconfig()\n",
    "    \n",
    "def widget_change_a(a):\n",
    "    config[\"a\"]=a.new\n",
    "    update_1()\n",
    "def widget_change_b(b):\n",
    "    config[\"b\"]=b.new\n",
    "    update_1()\n",
    "def widget_change_x(b):\n",
    "    config[\"xc\"]=b.new\n",
    "    update_1()\n",
    "def widget_change_y(b):\n",
    "    config[\"yc\"]=b.new\n",
    "    update_1()\n",
    "def widget_change_intensity_clip(b):\n",
    "    config[\"intensity_clip\"]=b.new\n",
    "    update_1()\n",
    "def widget_change_rg(b):\n",
    "    config[\"showclipping\"]=b.new\n",
    "    update_1()\n",
    "def widget_change_inv(c):\n",
    "    config[\"inv\"]=c.new\n",
    "    update_1()\n",
    "def wreset():\n",
    "    widget_unobserve()\n",
    "    slider3.min = 0\n",
    "    slider3.max = config[\"input_img\"].shape[0]\n",
    "    slider4.min = 0\n",
    "    slider4.max = config[\"input_img\"].shape[1]\n",
    "    slider1.value = config[\"intensity_clip\"]\n",
    "    slider3.value = config[\"yc\"]\n",
    "    slider4.value = config[\"xc\"]\n",
    "    check1.value = config[\"inv\"]\n",
    "    widget_observe()\n",
    "\n",
    "def resetconfig():\n",
    "    config[\"xc\"] = (0,config[\"input_img\"].shape[1])\n",
    "    config[\"yc\"] = (0,config[\"input_img\"].shape[0])\n",
    "    for ele in [\"inv\",\"intensity_clip\"]:\n",
    "        config[ele] = config_init[ele] \n",
    "    wreset()\n",
    "    update_1()\n",
    "\n",
    "def widget_reset(b):\n",
    "    resetconfig()\n",
    "    \n",
    "def updatefile(val):\n",
    "    update_img(np.array(Image.open(io.BytesIO(val.new[0].content.tobytes()))))\n",
    "\n",
    "def zoomfigure_func(b):\n",
    "    fig1.set_dpi(100*b.new)\n",
    "\n",
    "def zoomfigure_func1(b):\n",
    "    fig2.set_dpi(100*b.new)\n",
    "    \n",
    "def resetzoom_func(b):\n",
    "    floatslider.value = 1.5\n",
    "    floatslider1.value = 1.5\n",
    "\n",
    "slider1 = ipywidgets.FloatRangeSlider(value=config[\"intensity_clip\"],min=0,max=1,description=\"Intensity clip\",step=0.01)\n",
    "slider3 = ipywidgets.IntRangeSlider(value=config[\"yc\"],min=0,max=config[\"input_img\"].shape[0],description=\"y-crop\")\n",
    "slider4 = ipywidgets.IntRangeSlider(value=config[\"xc\"],min=0,max=config[\"input_img\"].shape[1],description=\"x-crop\")\n",
    "check1 = ipywidgets.Checkbox(value=config[\"inv\"],description=\"Inversion\")\n",
    "resetb = ipywidgets.Button(description=\"Reset\")\n",
    "fileup = ipywidgets.FileUpload()\n",
    "floatslider = ipywidgets.FloatSlider(min=0.2,max=5,value=1.5,description=\"Plot zoom\")\n",
    "floatslider1 = ipywidgets.FloatSlider(min=0.2,max=5,value=1.5,description=\"Hist. zoom\")\n",
    "resetzoom = ipywidgets.Button(description=\"Reset zoom\")\n",
    "resetzoom.on_click(resetzoom_func)\n",
    "\n",
    "resetb.on_click(widget_reset)\n",
    "def widget_observe():\n",
    "    slider1.observe(widget_change_intensity_clip,\"value\")\n",
    "    slider3.observe(widget_change_y,\"value\")\n",
    "    slider4.observe(widget_change_x,\"value\")\n",
    "    check1.observe(widget_change_inv,\"value\")\n",
    "    fileup.observe(updatefile,\"value\")\n",
    "    floatslider.observe(zoomfigure_func,\"value\")\n",
    "    floatslider1.observe(zoomfigure_func1,\"value\")\n",
    "    \n",
    "\n",
    "def widget_unobserve():\n",
    "    slider1.unobserve(widget_change_intensity_clip,\"value\")\n",
    "    slider3.unobserve(widget_change_y,\"value\")\n",
    "    slider4.unobserve(widget_change_x,\"value\")\n",
    "    check1.unobserve(widget_change_inv,\"value\")\n",
    "    fileup.unobserve(updatefile,\"value\")\n",
    "    floatslider.unobserve(zoomfigure_func,\"value\")\n",
    "    floatslider1.unobserve(zoomfigure_func1,\"value\")\n",
    "\n",
    "widget_observe()\n",
    "wreset()\n",
    "update_1(False)\n",
    "\n",
    "imgeditor = ipywidgets.HBox([ipywidgets.VBox([ipywidgets.HBox([fileup,resetb]),slider4,slider3,check1,slider1,floatslider,floatslider1,resetzoom,fig2.canvas],layout=ipywidgets.Layout(width=\"30%\",align_items=\"center\")),fig1.canvas],layout=ipywidgets.Layout())\n",
    "imgeditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24759a-99d2-4dcc-b3ef-4d3fcfe5481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"edited_img\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7fda2-355e-4298-8e66-04335ce1ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def predict_general_img(img,fn_model):\n",
    "    #split image in 512x512 tiles\n",
    "    sizey,sizex = img.shape\n",
    "    lix = [((j*512,min((j+1)*512,sizey)),(i*512,min((i+1)*512,sizex))) for j in range(int(np.ceil(sizey/512))) for i in range(int(np.ceil(sizex/512)))]\n",
    "    limgarray = []\n",
    "    for ele in lix:\n",
    "        pimg = img[ele[0][0]:ele[0][1],ele[1][0]:ele[1][1]]\n",
    "        nimg = np.ones((512,512))\n",
    "        nimg[:min(512,pimg.shape[0]),:min(512,pimg.shape[1])] = pimg\n",
    "        limgarray.append(nimg)\n",
    "    limgarray = np.array(limgarray)\n",
    "    #Predict label\n",
    "    lpredict = predict(limgarray,fn_model,batch_size=1,normalize_255=False)\n",
    "    if \"2023_model.keras\" in fn_model:\n",
    "        #Swap class index of 1 and 2, since for model 2023 the class indeces are (skyrmion:0, background:1, defects:2) and the functions are written for class indeces (skyrmion:0, defects:1, background:2)\n",
    "        lpredict[lpredict==1] = 5\n",
    "        lpredict[lpredict==2] = 1\n",
    "        lpredict[lpredict==5] = 2\n",
    "    #reconstruct full image from tiles\n",
    "    pred_label = np.zeros((sizey,sizex),dtype=lpredict.dtype)\n",
    "    for i,ele in enumerate(lix):\n",
    "        pred_label[ele[0][0]:ele[0][1],ele[1][0]:ele[1][1]] = lpredict[i,:ele[0][1]-ele[0][0],:ele[1][1]-ele[1][0]]\n",
    "    return pred_label\n",
    "\n",
    "def trafo_channel_to_rgb(I):\n",
    "    basis = np.array([[255,0,0],[0,255,0],[0,0,255],[255,255,0],[0,255,255]],dtype=np.uint8)\n",
    "    return basis[I]\n",
    "\n",
    "out = ipywidgets.Output()\n",
    "with out:\n",
    "    fig,ax = plt.subplots(ncols=2,dpi=100,figsize=(10,5))#,dpi=300)\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "ax[0].imshow(config[\"edited_img\"],cmap=\"gray\")\n",
    "tmpimg=np.ones_like(config[\"edited_img\"])\n",
    "im_pred = ax[1].imshow(tmpimg)\n",
    "ax[0].set_title(\"Kerr image\")\n",
    "ax[1].set_title(\"Predicted label\")\n",
    "ax[0].grid(False)\n",
    "ax[1].grid(False)\n",
    "fig.tight_layout()\n",
    "prediction = {}\n",
    "def zoomfigure_func(b):\n",
    "    fig.set_dpi(100*b.new)\n",
    "def resetzoom_func(b):\n",
    "    floatslider.value = 1.5\n",
    "def start_out():\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print(\"\",end=\"\\r\")\n",
    "def predict_func(b):\n",
    "    start_out()\n",
    "    with out:\n",
    "        prediction[\"label\"] = predict_general_img(config[\"edited_img\"],modelfndic[dropdown_model.value])\n",
    "        im_pred.set_data(trafo_channel_to_rgb(prediction[\"label\"])) \n",
    "button_predict = ipywidgets.Button(description=\"Predict\")\n",
    "modeldic = {\"Model 2023\":0,\"Model 2022\":1,\"Model 2022 inverse\":2}\n",
    "modelfndic = {0:'models/2023_model.keras',1:'models/2022_model.keras',2:'models/2022_model_inv.keras'}\n",
    "dropdown_model = ipywidgets.Dropdown(options=modeldic)\n",
    "floatslider = ipywidgets.FloatSlider(min=0.2,max=5,value=1.5,description=\"Plot zoom\")\n",
    "resetzoom = ipywidgets.Button(description=\"Reset zoom\")\n",
    "floatslider.observe(zoomfigure_func,\"value\")\n",
    "resetzoom.on_click(resetzoom_func)\n",
    "button_predict.on_click(predict_func)\n",
    "out = ipywidgets.Output()\n",
    "start_out()\n",
    "ipywidgets.VBox([ipywidgets.HBox([floatslider,resetzoom]),ipywidgets.HBox([dropdown_model,button_predict]),out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de82f2-ec34-4d88-ae10-5a4e75d5da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36f3e0-6305-4df5-8dc9-fa05a6125245",
   "metadata": {},
   "source": [
    "## Skyrmion extraction & selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb0b6b-262b-4a10-9dee-a40edec8366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def extract_skyrmions(pred_label):\n",
    "    _,labels,stats,posl = cv2.connectedComponentsWithStats((pred_label==0).astype(np.uint8),cv2.CV_32S)\n",
    "    #filter area\n",
    "    ixl,areal,posl = np.arange(1,len(stats)),stats[1:,4],posl[1:]\n",
    "    if selector[\"min_max_area\"] != None:\n",
    "        ixfilter = np.logical_and(areal>=selector[\"min_max_area\"][0],areal<=selector[\"min_max_area\"][1])\n",
    "        ixl,areal,posl = ixl[ixfilter],areal[ixfilter],posl[ixfilter]\n",
    "    ixsort = np.argsort(areal)[::-1]\n",
    "    ixl,areal,posl = ixl[ixsort],areal[ixsort],posl[ixsort]\n",
    "    ixlabel = np.zeros(np.max(labels)+1,dtype=np.int64)\n",
    "    ixlabel[ixl] = np.arange(1,1+len(ixl))\n",
    "    labels = ixlabel[labels]\n",
    "\n",
    "    colmap = np.vstack((np.ones(3),0.87*np.random.rand(np.max(labels),3)))\n",
    "    cont,_ = cv2.findContours((labels!=0).astype(np.uint8),cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    radiusl = np.sqrt(areal/np.pi)\n",
    "    return labels,posl,areal,colmap,cont,radiusl\n",
    "\n",
    "def update_selector(selector):\n",
    "    labels,posl,areal,colmap,cont,radiusl = extract_skyrmions(prediction[\"label\"])\n",
    "    selector.update({\"labels\":labels,\"posl\":posl,\"areal\":areal,\"colmap\":colmap,\"cont\":cont,\"radiusl\":radiusl})\n",
    "    \n",
    "selector = {\"min_max_area\":None,\"pred\":prediction[\"label\"]}\n",
    "update_selector(selector)\n",
    "selector[\"rbins\"] = np.linspace(np.min(selector[\"radiusl\"]),np.max(selector[\"radiusl\"]),40)\n",
    "\n",
    "fig = plt.figure(dpi=100,figsize=(10,6))\n",
    "fig.canvas.header_visible = False\n",
    "gs = fig.add_gridspec(2,2,height_ratios=[1,0.3])\n",
    "ax = [fig.add_subplot(gs[0,0]),fig.add_subplot(gs[0,1]),fig.add_subplot(gs[1,:])]\n",
    "im1 = ax[0].imshow(selector[\"colmap\"][selector[\"labels\"]])\n",
    "im2 = ax[1].imshow(config[\"edited_img\"],cmap=\"gray\")\n",
    "\n",
    "lcontobj =  []\n",
    "for i in range(len(selector[\"cont\"])):\n",
    "    lx,ly = list(selector[\"cont\"][i][:,0,0]),list(selector[\"cont\"][i][:,0,1])\n",
    "    lcontobj.append(ax[1].plot(lx+[lx[0]],ly+[ly[0]],color=\"r\",lw=0.5)[0])\n",
    "ax[1].set_title(\"Skyrmion contours\")\n",
    "ax[0].set_title(\"Single skyrmion mask\")\n",
    "ax[0].grid(False)\n",
    "ax[1].grid(False)\n",
    "\n",
    "_,_,hist = ax[2].hist(selector[\"radiusl\"],bins=selector[\"rbins\"])\n",
    "meanrhist =  ax[2].axvline(np.mean(selector[\"radiusl\"]),color=\"red\",lw=3,label=\"Mean value\")\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel(r\"Radius $r=\\sqrt{A/\\pi}$ [pixel]\")\n",
    "ax[2].set_ylabel(r\"Frequency\")\n",
    "ax[2].set_title(\"Skyrmion radius statistic\")\n",
    "fig.tight_layout()\n",
    "def zoomfigure_func(b):\n",
    "    fig.set_dpi(100*b.new)\n",
    "def resetzoom_func(b):\n",
    "    floatslider.value = 1.5\n",
    "def select_func(b):\n",
    "    while len(lcontobj)>0:\n",
    "        obj = lcontobj.pop()\n",
    "        obj.remove()\n",
    "    selector[\"min_max_area\"] = (selradius.value[0]**2*np.pi,selradius.value[1]**2*np.pi)\n",
    "    update_selector(selector)\n",
    "    for i in range(len(selector[\"cont\"])):\n",
    "        lx,ly = list(selector[\"cont\"][i][:,0,0]),list(selector[\"cont\"][i][:,0,1])\n",
    "        lcontobj.append(ax[1].plot(lx+[lx[0]],ly+[ly[0]],color=\"r\",lw=0.5)[0])\n",
    "    im1.set_data(selector[\"colmap\"][selector[\"labels\"]])\n",
    "    im2.set_data(config[\"edited_img\"])\n",
    "    \n",
    "    nhist = np.histogram(selector[\"radiusl\"],selector[\"rbins\"],density=True)[0]\n",
    "    for i,ele in enumerate(hist):\n",
    "        ele.set_height(nhist[i])\n",
    "    ax[2].set_ylim(0,np.max(nhist)*1.1)\n",
    "    meanrhist.set_xdata([np.mean(selector[\"radiusl\"]),np.mean(selector[\"radiusl\"])])\n",
    "\n",
    "floatslider = ipywidgets.FloatSlider(min=0.2,max=5,value=1.5,description=\"Plot zoom\")\n",
    "resetzoom = ipywidgets.Button(description=\"Reset zoom\")\n",
    "floatslider.observe(zoomfigure_func,\"value\")\n",
    "resetzoom.on_click(resetzoom_func)\n",
    "\n",
    "minr,maxr = np.min(selector[\"radiusl\"]),np.max(selector[\"radiusl\"])\n",
    "selradius = ipywidgets.FloatRangeSlider(value=(minr,maxr),min=minr,max=maxr,readout_format=\".1f\",description=\"Radius range\",step=0.01)\n",
    "selradius.layout.width=\"40%\"\n",
    "selradius.observe(select_func,\"value\")\n",
    "\n",
    "ipywidgets.VBox([ipywidgets.HBox([floatslider,resetzoom]),ipywidgets.HBox([selradius])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca4f5e-7512-428b-b645-9a698d38285a",
   "metadata": {},
   "source": [
    "## Saving extracted data in a pandas DataFrame & CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d0e2a-568e-4713-9ca0-993cf4753065",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\"pos_x [pixel]\":selector[\"posl\"][:,0],\"pos_y [pixel]\":selector[\"posl\"][:,1],\"area [pixel*pixel]\":selector[\"areal\"]})\n",
    "dataframe.to_csv(\"extracted_skyrmion_data_table.csv\",sep=\";\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ca730-e0b2-4a55-85fd-665cee765fc4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Determination of average skyrmion-skyrmion distance\n",
    "Baesd on the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9e9a4-d06c-47ab-9ae5-e3be6ee6723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def calculate_voronoi_delunay(posl):\n",
    "    voronoi = scipy.spatial.Voronoi(posl)\n",
    "    delaunay = scipy.spatial.Delaunay(posl)\n",
    "    return voronoi,delaunay\n",
    "\n",
    "def calculate_sky_sky_distance(voronoi,delaunay,posl,angle_lim):\n",
    "    lcon,lcon1 = [],[]\n",
    "    #selector out triangles with small angles (only occurs at the boundary of the image; therefore, they do not represent real skyrmion distances)\n",
    "    for ele in delaunay.simplices:\n",
    "        ok = True\n",
    "        for i in range(len(ele)):\n",
    "            v1,v2 = delaunay.points[ele[(i+1)%len(ele)]]-delaunay.points[ele[i]],delaunay.points[ele[(i-1)%len(ele)]]-delaunay.points[ele[i]]\n",
    "            if not (np.pi/180*angle_lim[0]<=np.arccos(np.clip(np.dot(v1,v2)/np.sqrt(np.dot(v1,v1)*np.dot(v2,v2)),-1,1))<=np.pi/180*angle_lim[1]):\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            for i in range(len(ele)):\n",
    "                a,b = ele[i],ele[(i+1)%len(ele)]\n",
    "                lcon.append((min(a,b),max(a,b)))\n",
    "        else:\n",
    "            for i in range(len(ele)):\n",
    "                a,b = ele[i],ele[(i+1)%len(ele)]\n",
    "                lcon1.append((min(a,b),max(a,b)))\n",
    "            \n",
    "    lcon = list(set(lcon))\n",
    "    lcon1 = list(set(lcon1)-set(lcon))\n",
    "    distance = [np.linalg.norm(posl[a]-posl[b]) for a,b in lcon]\n",
    "    return distance,lcon,lcon1\n",
    "\n",
    "def update_dist(dist):\n",
    "    if (\"voronoi\" not in dist) or (\"delaunay\" not in dist):\n",
    "        dist[\"voronoi\"],dist[\"delaunay\"] = calculate_voronoi_delunay(dist[\"posl\"])\n",
    "    \n",
    "    distance,lcon,lcon1 = calculate_sky_sky_distance(dist[\"voronoi\"],dist[\"delaunay\"],dist[\"posl\"],dist[\"angle_lim\"])\n",
    "    dist.update({\"distance\":distance,\"lcon\":lcon,\"lcon1\":lcon1})\n",
    "\n",
    "dist = {\"posl\":selector[\"posl\"],\"angle_lim\":(0,180)}\n",
    "update_dist(dist)\n",
    "\n",
    "fig = plt.figure(dpi=100,figsize=(10,10))\n",
    "fig.canvas.header_visible = False\n",
    "gs = fig.add_gridspec(2,1,height_ratios=[2,0.5])\n",
    "ax = [fig.add_subplot(gs[0]),fig.add_subplot(gs[1])]\n",
    "\n",
    "#ax[0].plot(dist[\"posl\"][:,0],dist[\"posl\"][:,1],\"ro\",ms=0.3)\n",
    "\n",
    "for ele in dist[\"voronoi\"].regions:\n",
    "    if len(ele)==0 or len(list(filter(lambda x:x==-1,ele)))>0: continue\n",
    "    ax[0].plot([dist[\"voronoi\"].vertices[i,0] for i in list(ele)+[ele[0]]],[dist[\"voronoi\"].vertices[i,1] for i in list(ele)+[ele[0]]],lw=1.5,color=\"b\")\n",
    "\n",
    "lobj = []\n",
    "\n",
    "for a,b in dist[\"lcon\"]:\n",
    "    lobj.append(ax[0].plot([dist[\"posl\"][a,0],dist[\"posl\"][b,0]],[dist[\"posl\"][a,1],dist[\"posl\"][b,1]],color=\"r\",lw=1)[0])\n",
    "    \n",
    "for a,b in dist[\"lcon1\"]:\n",
    "    lobj.append(ax[0].plot([dist[\"posl\"][a,0],dist[\"posl\"][b,0]],[dist[\"posl\"][a,1],dist[\"posl\"][b,1]],color=\"g\",lw=1)[0])\n",
    "\n",
    "ax[0].set_xlim(0,config[\"edited_img\"].shape[1])\n",
    "ax[0].set_ylim(config[\"edited_img\"].shape[0],0)\n",
    "ax[0].imshow(config[\"edited_img\"],cmap=\"gray\",origin=\"lower\")\n",
    "ax[0].set_title(\"Delaunay triangulation result\")\n",
    "ax[0].grid(False)\n",
    "yh,xh,hist = ax[1].hist(dist[\"distance\"],color='#1f77b4',density=True)\n",
    "histmean = ax[1].axvline(np.mean(dist[\"distance\"]),color=\"red\",lw=3,label=\"Periodicity\")\n",
    "lobj += [hist,histmean]\n",
    "ax[1].set_ylim(0,np.max(yh)*1.2)\n",
    "ax[1].set_xlim(np.min(xh),np.max(xh))\n",
    "ax[1].set_xlabel(r\"Skyrmion-Skyrmion distance [pixel]\")\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel(r\"Frequency\")\n",
    "ax[1].set_title(\"Skyrmion-Skyrmion statistic\")\n",
    "fig.tight_layout()\n",
    "\n",
    "def zoomfigure_func(b):\n",
    "    fig.set_dpi(100*b.new)\n",
    "def resetzoom_func(b):\n",
    "    floatslider.value = 1.5\n",
    "def angle_func(update_val):\n",
    "    while len(lobj)>0:\n",
    "        obj = lobj.pop()\n",
    "        obj.remove()\n",
    "\n",
    "    dist[\"angle_lim\"] = update_val.new\n",
    "    update_dist(dist)\n",
    "        \n",
    "    for a,b in dist[\"lcon\"]:\n",
    "        lobj.append(ax[0].plot([dist[\"posl\"][a,0],dist[\"posl\"][b,0]],[dist[\"posl\"][a,1],dist[\"posl\"][b,1]],color=\"r\",lw=1)[0])\n",
    "    \n",
    "    for a,b in dist[\"lcon1\"]:\n",
    "        lobj.append(ax[0].plot([dist[\"posl\"][a,0],dist[\"posl\"][b,0]],[dist[\"posl\"][a,1],dist[\"posl\"][b,1]],color=\"g\",lw=1)[0])\n",
    "\n",
    "    if len(dist[\"distance\"])>0:\n",
    "        yh,xh,histobj = ax[1].hist(dist[\"distance\"],color='#1f77b4',density=True)\n",
    "        histmean = ax[1].axvline(np.mean(dist[\"distance\"]),color=\"red\",lw=3,label=\"Periodicity\")\n",
    "        lobj.append(histobj)\n",
    "        lobj.append(histmean)\n",
    "        ax[1].set_ylim(0,np.max(yh)*1.2)\n",
    "        ax[1].set_xlim(np.min(xh),np.max(xh))\n",
    "        \n",
    "\n",
    "\n",
    "floatslider = ipywidgets.FloatSlider(min=0.2,max=5,value=1.5,description=\"Plot zoom\")\n",
    "resetzoom = ipywidgets.Button(description=\"Reset zoom\")\n",
    "floatslider.observe(zoomfigure_func,\"value\")\n",
    "resetzoom.on_click(resetzoom_func)\n",
    "\n",
    "minr,maxr = np.min(selector[\"radiusl\"]),np.max(selector[\"radiusl\"])\n",
    "selradius = ipywidgets.FloatRangeSlider(value=(minr,maxr),min=minr,max=maxr,readout_format=\".1f\",description=\"Radius range\",step=0.01)\n",
    "selradius.layout.width=\"40%\"\n",
    "selradius.observe(select_func,\"value\")\n",
    "\n",
    "selradius = ipywidgets.FloatRangeSlider(value=(0,180),min=0,max=180,readout_format=\".1f\",description=\"Angle range\",step=0.01)\n",
    "selradius.layout.width=\"40%\"\n",
    "selradius.observe(angle_func,\"value\")\n",
    "\n",
    "ipywidgets.VBox([ipywidgets.HBox([floatslider,resetzoom]),selradius])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f4270-cec7-4270-bf68-0c7ea1aeff22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
